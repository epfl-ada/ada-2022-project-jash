{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('./data/actor_movie_combi.csv', sep=',')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scraping_values(soup, attributes):\n",
    "    \"\"\"This function is used to scrape particular attributes from webpages.\"\"\"\n",
    "    attribute_dict = {}\n",
    "    normal = True  # flag to show whether the value is in dollar.\n",
    "    empty = True # flag to show whether the movie has budget or gross data.\n",
    "\n",
    "    for i in range(len(attributes)):\n",
    "        try:\n",
    "            value = soup.find_all('li', attrs={'data-testid': f'title-boxoffice-{attributes[i]}'})[0].div.ul.li.label.text.split(\" \")[0]\n",
    "            if value.startswith(\"$\"):\n",
    "                attribute_dict[attributes[i]] = int(value[1:].replace(\",\", \"\"))\n",
    "            else:\n",
    "                attribute_dict[attributes[i]] = value\n",
    "                normal = False\n",
    "            empty = False\n",
    "        except:\n",
    "            attribute_dict[attributes[i]] = \"NA\"\n",
    "    \n",
    "    return attribute_dict, empty, normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = dataset[\"tconst\"].unique()\n",
    "temp_dataset = list(temp[150000:150100])\n",
    "len(temp_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'authority': 'www.imdb.com',\n",
    "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "    'accept-language': 'zh-CN,zh;q=0.9,en;q=0.8',\n",
    "    'cache-control': 'max-age=0',\n",
    "    # 'cookie': 'ubid-main=134-2457033-3328462; _gcl_au=1.1.1240392916.1671623441; uu=eyJpZCI6InV1MTljYjBjN2M2NGIxNDM3MGFmOWMiLCJwcmVmZXJlbmNlcyI6eyJmaW5kX2luY2x1ZGVfYWR1bHQiOmZhbHNlfX0=; session-id=132-9104638-2602903; _uetsid=b201d760812511edb1c173c28205e682; _uetvid=b2023d60812511eda00d4bfa409b648d; session-id-time=2082787201l; session-token=fR2NwJcCdHJ6KfiMWEo4Z19rX4XCLsIxF9LEnomVgw1g8mO4qGfF0ChE2EzG5PEbMJfv/bb2DT95oo3WDdicZTEm3gjoiQjdKHD6TvOxFc4BnIHNB3+noazoV5MxcO8cJK5cvxf0x2iI2tmb47Qh/nStfNAO3B12YJhjUg529J3LeTjLdTijnYP5CYgdWKksJ/Kdgk+AxFoazRf98G+9Hw==; csm-hit=tb:PM6ZQFAWZD0JK3RETJVW+s-PM6ZQFAWZD0JK3RETJVW|1671659311034&t:1671659311034&adb:adblk_no',\n",
    "    'sec-ch-ua': '\"Not?A_Brand\";v=\"8\", \"Chromium\";v=\"108\", \"Google Chrome\";v=\"108\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'sec-ch-ua-platform': '\"macOS\"',\n",
    "    'sec-fetch-dest': 'document',\n",
    "    'sec-fetch-mode': 'navigate',\n",
    "    'sec-fetch-site': 'same-origin',\n",
    "    'sec-fetch-user': '?1',\n",
    "    'upgrade-insecure-requests': '1',\n",
    "    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36',\n",
    "}\n",
    "\n",
    "attributes = [\"budget\", \"grossdomestic\", \"openingweekenddomestic\", \"cumulativeworldwidegross\"]\n",
    "movies = []\n",
    "outliers = []\n",
    "\n",
    "for i in range(len(temp_dataset)):\n",
    "    movie_id = temp_dataset[i]\n",
    "    response = requests.get(f'https://www.imdb.com/title/{movie_id}/', headers=headers)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    attribute_values, empty, normal = scraping_values(soup, attributes)\n",
    "    if not empty:\n",
    "        attribute_values[\"tconst\"] = movie_id\n",
    "        if normal:\n",
    "            movies.append(attribute_values)\n",
    "        else:\n",
    "            outliers.append(attribute_values)\n",
    "\n",
    "if len(movies) > 0:\n",
    "    revenue_data_per_movie = {}\n",
    "    attributes += [\"tconst\"]\n",
    "    for attr in attributes:\n",
    "        revenue_data_per_movie[attr] = [movie[attr] for movie in movies]\n",
    "\n",
    "    revenue_data_per_movie = pd.DataFrame(revenue_data_per_movie)\n",
    "    revenue_data_per_movie.to_csv(\"data/revenue_data_per_movie.csv\")\n",
    "    revenue_data_per_movie.head()\n",
    "else:\n",
    "    print(\"No movie has revenue data in this sweep.\")\n",
    "\n",
    "if len(outliers) > 0:\n",
    "    revenue_outliers = {}\n",
    "    if \"tconst\" not in attributes:\n",
    "        attributes += [\"tconst\"]\n",
    "        \n",
    "    for attr in attributes:\n",
    "        revenue_outliers[attr] = [outlier[attr] for outlier in outliers]\n",
    "\n",
    "    revenue_outliers = pd.DataFrame(revenue_outliers)\n",
    "    revenue_outliers.to_csv(\"data/revenue_outliers.csv\")\n",
    "    revenue_outliers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revenue_outliers.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web scraping movie revenues"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('ada')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "63b0f96a7ed47cef9ab35015ef1216089d7ec8d8d7aec9bdd2a146a1ec72f473"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
